{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering with Learn-It\n",
    "\n",
    "In this notebook, you will learn how to develop your own feature extractor. The idea of a new feature does not come out spontaneously. Instead, you might need to analyze erros with a current feature set and consider what would be a good next step. \n",
    "\n",
    "The workflow is often called \"feature engineering\" and is considered an art of data scientists and machine learning engineers. Feature engineering is more promising work than model selection and hyper-parameter tuning. \n",
    "\n",
    "A general workflow of feature engineering looks like as follows:\n",
    "\n",
    "- Step 1 (Ideation) Think of missing information that does not exist in the current feature set.\n",
    "- Step 2 (Development) Develop the idea in Python code.\n",
    "- Step 3 (Verification) Verify if the developed code works.\n",
    "- Step 4 (Deployment) Incorporate the developed code into the framework.\n",
    "\n",
    "Step 1 is the most important step which cannot be automated and has no silver bullet for it. ML engineers always need to carefully analyze errors with the current feature set and try to discuss if there is room for improvement following their domain knowledge on the task.\n",
    "\n",
    "Learn-It offers intuitive workflow for Step 2 - 4 so you can focus on Step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Develop Your Own Feature Extraction Algorithm?\n",
    "\n",
    "Learn-It currently uses `scikit-learn` as a machine-learning core library. In this notebook, we refer a \"feature extractor\" as a \"transformer\" so please consider these words are interchangeable. \n",
    "\n",
    "Conceptually, a transformer can take into account more than one columns to derive feature values from them. For simplicity, we only consider \"one-column\" feature extractors in this notebook. \n",
    "\n",
    "Below is a figure that shows the image of how a transformer extracts feature values from a column.\n",
    "\n",
    "<image>\n",
    "\n",
    "Here is an example of a user-defined transformer class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Example: Name Title Extractor\n",
    "\n",
    "The following example transformer extracts and encodes \"Title\" information of person names into 0/1-valued vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TitleEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,\n",
    "                 title_list=None):\n",
    "        if title_list is None:\n",
    "            title_list = [\"Mr.\",\n",
    "                          \"Ms.\"\n",
    "                          \"Mrs.\",\n",
    "                          \"Miss.\"]\n",
    "        self.title_list = title_list\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # X is np.array\n",
    "        s = pd.Series(X[:, 0])\n",
    "        s_list = []\n",
    "        for title in self.title_list:\n",
    "            s_list.append(s.apply(lambda x: title in x).astype(\"int\"))\n",
    "        df = pd.concat(s_list, axis=1)\n",
    "        df.loc[:, \"None\"] = (df.sum(axis=1) == 0).astype(\"int\")\n",
    "        return df.as_matrix()\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return self.title_list + [\"Others\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at each function for detail.\n",
    "\n",
    "### `__init__()`\n",
    "\n",
    "This `__init__` function receives `title_list` so that the user can customize\n",
    "the title list. For instance, someone might want to incorporate \"Prof.\" and\n",
    "\"Dr.\" in addition to the common titles. In this case, the four titles will be\n",
    "used by default.\n",
    "\n",
    "\n",
    "### `fit()`\n",
    "\n",
    "This example does nothing in the training phase. The function must return\n",
    "`self` by definition. Please note that this function should store information \n",
    "if the transformer fits data dynamically to define features. For instance, Bag-of-Words transformer should keep vocaburaly information in `fit()` function. In this example, the order of features are defined by the order of elements in `self.title_list` so `fit()` has to do nothing.\n",
    "\n",
    "\n",
    "### `transform()`\n",
    "\n",
    "This is the main function of the feature transformer class. In this example, `transform()` judges if any titles appear in each person name. If no title appears, it activates \"Other\" flag. \n",
    "\n",
    "The input variable `X` is `np.ndarray` of the shape `(N, 1)` where `N` is the total number of rows in the input data. Therefore, you need to convert `np.ndarray` into any convenient data structure for your feature extraction algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Your Transformer Class\n",
    "\n",
    "It is very difficult to implement a transformer class without any bug from the beginning. Learn-It offers a test function that verifies if your own transformer class can successfully extract feature values from input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature(s) successfully extracted! :)\n",
      "# of features=4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(\"../\")\n",
    "from learnit import AutoConverter\n",
    "# TODO: from learnit import check_transformer\n",
    "from learnit.autoconverter.autoconverter import check_transformer\n",
    "\n",
    "input_df = pd.read_csv(\"data/train.csv\")\n",
    "# It returns extracted `X` in the form of `np.ndarray`\n",
    "X = check_transformer(input_df, \"Name\", TitleEncoder())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. How to Incorporate Your Transformer to Learn-It\n",
    "\n",
    "Now, `TitleEncoder` is ready to use for the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# This is how we use AutoConverter with default settings\n",
    "ac_old = AutoConverter(target=\"Survived\")\n",
    "X_old, y_old = ac_old.fit_transform(input_df)\n",
    "\n",
    "# This is how we make AutoConverter apply \"TitleEncoder\"  to \"Name\" column of the dataset\n",
    "ac_new = AutoConverter(target=\"Survived\",\n",
    "                                             column_converters={\"Name\": [(TitleEncoder, {})]})\n",
    "X_new, y_new = ac_new.fit_transform(input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look if the configuration changes the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_old.shape=(881, 1215)\n",
      "X_new.shape=(881, 708)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_old.shape={}\".format(X_old.shape))\n",
    "print(\"X_new.shape={}\".format(X_new.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new `AutoConverter` instance extracts fewer features than before because the new one extracts only 5 features instead of several hundreds of TF-IDF weighted bag-of-word features.\n",
    "\n",
    "The default setting \"overwrites\" transformers applied to a target column (\"Name\" in this example) so default transformers such as `TfIdfVectorizer` for \"textual\" type columns will NOT be applied to the column if you manually configure `column_converters`.\n",
    "\n",
    "If you want to \"add\" your own transformer in addition to default transformers. Use `use_column_converter_only=False` option with `AutoConverter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_new2.shape=(881, 1219)\n"
     ]
    }
   ],
   "source": [
    "ac_new2 = AutoConverter(target=\"Survived\",\n",
    "                                               column_converters={\"Name\": [(TitleEncoder, {})]},\n",
    "                                               use_column_converter_only=False)\n",
    "X_new2, y_new2 = ac_new2.fit_transform(input_df)\n",
    "print(\"X_new2.shape={}\".format(X_new2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary: Transformer Template Class\n",
    "\n",
    "This notebook has introduced how to develop, verify and deploy your own transformer with Learn-It. The workflow will involve a lot of trial-and-errors but Learn-It should reduce the significant amount of workload on the feature engineering tasks.\n",
    "\n",
    "Below is a transformer template so you can copy and use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerTemplate(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, *args):\n",
    "        ##\n",
    "        ## Implement initialization step\n",
    "        ##\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        ##\n",
    "        ## Implement training logic if necessary\n",
    "        ## Leave it if the transformer does nothing in the training phase\n",
    "        ##\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        ## \n",
    "        ## Implement a transform function that returns a feature vector/matrix.\n",
    "        ## The returned value should be (N, M) where N is the number of input data\n",
    "        ## and M is the total number of features that are extracted by this function.\n",
    "        ##\n",
    "        return [[1] * len(X)]\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        ##\n",
    "        ## [Optional] Describe feature name(s)\n",
    "        ##\n",
    "        return [\"feature name\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
